{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88902b0",
   "metadata": {},
   "source": [
    "#  ASSIGNMENT-1_WEB SCRAPING_using BeautifulSoup :-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22c202",
   "metadata": {},
   "source": [
    "- BeautifulSoup Documentation = https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61cd1e4",
   "metadata": {},
   "source": [
    "**In all the following questions, you have to use BeautifulSoup to scrape different websites and collect data as per\n",
    "the requirement of the question.**\n",
    "\n",
    "**Every answer to the question should be in form of a python function which should take URL as the parameter.\n",
    "Use Jupyter Notebooks to program, upload it on your GitHub and send the link of the Jupyter notebook to\n",
    "your SME.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bddb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: html5lib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.0b8)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# INSTALLING REQUIRED LIBRARIES:\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d46abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING REQUIRED LIBRARIES:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9166ff",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display **all the header tags** from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fb6d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting web page to get access of the source code.\n",
    "\n",
    "url1 = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "url1 # <Response [200]>: Access Granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99cd40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Full Page's Content of wikipedia.org/wiki/Main_Page.\n",
    "\n",
    "soup1 = BeautifulSoup(url1.content)\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4dea2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping all the Header tags:\n",
    "\n",
    "header1= [i.text for i in soup1.find_all(class_=\"mw-headline\")]\n",
    "#header1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ccb2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         HEADERS\n",
       "1           Welcome to Wikipedia\n",
       "2  From today's featured article\n",
       "3               Did you know ...\n",
       "4                    In the news\n",
       "5                    On this day\n",
       "6       Today's featured picture\n",
       "7       Other areas of Wikipedia\n",
       "8    Wikipedia's sister projects\n",
       "9            Wikipedia languages"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"HEADERS\": header1})\n",
    "df1.index += 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3b0fc",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7558d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving url:\n",
    "url2 = \"https://www.imdb.com/list/ls091520106/\"\n",
    "\n",
    "# Requesting to obtain source code:\n",
    "page2 = requests.get(url2) \n",
    "\n",
    "# Getting page content:\n",
    "htmlContent2 = page2.content \n",
    "soup2 = BeautifulSoup(htmlContent2,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a68584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, rating, year of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93526b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Shawshank Redemption'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title1 = BeautifulSoup('<a href=\"/title/tt0111161/?ref_=ttls_li_tt\">The Shawshank Redemption</a>','html.parser')\n",
    "title1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65f9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top Movies name\n",
    "\n",
    "name = soup2.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "\n",
    "# get text from movie name web elements\n",
    "\n",
    "movies_name = [] #empty list\n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "\n",
    "        movies_name.append(j.text)\n",
    "        \n",
    "#movies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f29949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB-Ratings:\n",
    "\n",
    "num = soup2.find_all('div',class_=\"ipl-rating-star small\")\n",
    "\n",
    "rating = []\n",
    "\n",
    "for n in num:\n",
    "    for r in n.find_all(\"span\",class_=\"ipl-rating-star__rating\"):\n",
    "        rating.append(r.text)\n",
    "    \n",
    "#rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dadb7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year of Release: span  class=\"lister-item-year text-muted unbold\"\n",
    "\n",
    "YoR=[i.text for i in soup2.find_all(class_=\"lister-item-year text-muted unbold\")]\n",
    "#YoR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb81301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Check Length before constructing the table.\n",
    "print(len(movies_name),len(rating),len(YoR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "087af4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Movie Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Movie name Movie Rating Year of Release\n",
       "1               The Shawshank Redemption          9.3          (1994)\n",
       "2                          The Godfather          9.2          (1972)\n",
       "3                  The Godfather Part II            9          (1974)\n",
       "4                        The Dark Knight            9          (2008)\n",
       "5                           12 Angry Men            9          (1957)\n",
       "..                                   ...          ...             ...\n",
       "96                    North by Northwest          8.3          (1959)\n",
       "97                    A Clockwork Orange          8.3          (1971)\n",
       "98                                Snatch          8.2          (2000)\n",
       "99   Le fabuleux destin d'Amélie Poulain          8.3          (2001)\n",
       "100                              The Kid          8.3          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forming DataFrame:\n",
    "\n",
    "df2 = pd.DataFrame({'Movie name':movies_name, 'Movie Rating':rating, 'Year of Release':YoR})\n",
    "df2.index += 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f117f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d1ec40",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d73b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving url:\n",
    "url3 = \"https://www.imdb.com/india/top-rated-indian-movies/?sort=ir,desc&mode=simple&page=1\"\n",
    "\n",
    "# Requesting to obtain source code:\n",
    "page3 = requests.get(url3) \n",
    "\n",
    "# Getting page content:\n",
    "htmlContent3 = page3.content \n",
    "soup3 = BeautifulSoup(htmlContent3,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3783914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie-Name:\n",
    "\n",
    "name = soup3.find_all('td',class_=\"titleColumn\",limit=100)\n",
    "\n",
    "Movie_Name = []\n",
    "\n",
    "for n in name:\n",
    "    for r in n.find_all(\"a\"):\n",
    "        Movie_Name.append(r.text)\n",
    "    \n",
    "# Movie_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f82109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB-Ratings:\n",
    "\n",
    "num = soup3.find_all('td',class_=\"ratingColumn imdbRating\",limit=100)\n",
    "\n",
    "rating = []\n",
    "\n",
    "for n in num:\n",
    "    for r in n.find_all(\"strong\"):\n",
    "        rating.append(r.text)\n",
    "    \n",
    "# rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c3dc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year of release:\n",
    "\n",
    "YoR = []\n",
    "\n",
    "for i in soup3.find_all('span',class_=\"secondaryInfo\", limit=100):\n",
    "    YoR.append(i.text)\n",
    "\n",
    "# YoR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ce2f58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Movie_Name),len(rating),len(YoR)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "670246d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Movie Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kantara</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ustad Hotel</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Theeran Adhigaaram Ondru</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Angoor</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(1982)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Movie name Movie Rating Year of Release\n",
       "1                                Kantara          8.5          (2022)\n",
       "2    Ramayana: The Legend of Prince Rama          8.5          (1993)\n",
       "3             Rocketry: The Nambi Effect          8.4          (2022)\n",
       "4                                Nayakan          8.4          (1987)\n",
       "5                             Anbe Sivam          8.4          (2003)\n",
       "..                                   ...          ...             ...\n",
       "96                           Ustad Hotel          8.0          (2012)\n",
       "97              Theeran Adhigaaram Ondru          8.0          (2017)\n",
       "98                       Rang De Basanti          8.0          (2006)\n",
       "99           Baahubali 2: The Conclusion          8.0          (2017)\n",
       "100                               Angoor          8.0          (1982)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forming DataFrame:\n",
    "\n",
    "df = pd.DataFrame({'Movie name':Movie_Name, 'Movie Rating':rating, 'Year of Release':YoR})\n",
    "df.index += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf05ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a518cf39",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06052055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving url:\n",
    "url4 = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "\n",
    "# Requesting to obtain source code:\n",
    "page4 = requests.get(url4) \n",
    "\n",
    "# Getting page content:\n",
    "htmlContent4 = page4.content \n",
    "soup4 = BeautifulSoup(htmlContent4,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77b5fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presidents Of India List: \n",
    "\n",
    "PoI = []\n",
    "\n",
    "for i in soup4.find_all('h3'):\n",
    "    PoI.append(i.text)\n",
    "\n",
    "#PoI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55720c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TERM OF OFFICE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8239211",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tenure = []\n",
    "\n",
    "for i in soup4.find_all('p',limit=18):\n",
    "    Tenure.append(i.text.replace(\"Term of Office: \",\"\")) # .split(',')) Tenure.append(i.text[16:50]) .append(i.get_text().replace(\"\\n\",\"\")) \n",
    "#Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505a129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to remove multiple elements from a list\n",
    " \n",
    "# given index of elements to be removed:\n",
    "unwanted = [1,3,5,7]\n",
    " \n",
    "for ele in sorted(unwanted, reverse = True):\n",
    "    del Tenure[ele]\n",
    "    \n",
    "term = Tenure\n",
    "#term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7263e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Former_PoI</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Former_PoI  \\\n",
       "1           Shri Ram Nath Kovind (birth - 1945)   \n",
       "2             Shri Pranab Mukherjee (1935-2020)   \n",
       "3   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "4            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "5            Shri K. R. Narayanan (1920 - 2005)   \n",
       "6           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "7               Shri R Venkataraman (1910-2009)   \n",
       "8                  Giani Zail Singh (1916-1994)   \n",
       "9         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "10         Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "11     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "12                 Dr. Zakir Husain (1897-1969)   \n",
       "13     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "14             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                       Term of Office  \n",
       "1                     25 July, 2017 to 25 July, 2022   \n",
       "2                     25 July, 2012 to 25 July, 2017   \n",
       "3                     25 July, 2007 to 25 July, 2012   \n",
       "4                     25 July, 2002 to 25 July, 2007   \n",
       "5                     25 July, 1997 to 25 July, 2002   \n",
       "6                     25 July, 1992 to 25 July, 1997   \n",
       "7                     25 July, 1987 to 25 July, 1992   \n",
       "8                     25 July, 1982 to 25 July, 1987   \n",
       "9                     25 July, 1977 to 25 July, 1982   \n",
       "10               24 August, 1974 to 11 February, 1977  \n",
       "11  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
       "12                        13 May, 1967 to 3 May, 1969  \n",
       "13                       13 May, 1962 to 13 May, 1967  \n",
       "14                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forming DataFrame:\n",
    "\n",
    "df4 = pd.DataFrame({'Former_PoI':PoI, 'Term of Office':term})\n",
    "df4.index += 1\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78636f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a51999fb",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "- a) Top 10 ODI **teams** in men’s cricket along with the records for **matches, points and rating**.\n",
    "- b) Top 10 ODI **Batsmen** along with the records of their **team and rating**.\n",
    "- c) Top 10 ODI **bowlers** along with the records of their **team and rating**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d500fc5",
   "metadata": {},
   "source": [
    "**a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "126b788c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5a = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a8d6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5a = BeautifulSoup(page5a.content)\n",
    "#soup5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbdf2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teams:\n",
    "\n",
    "Team = []\n",
    "\n",
    "for i in soup5a.find_all('span',class_=\"u-hide-phablet\",limit=10):\n",
    "    Team.append(i.text)\n",
    "\n",
    "#Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "211be01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches:\n",
    "\n",
    "match1 = []\n",
    "\n",
    "for i in soup5a.find_all('td',class_ = \"rankings-block__banner--matches\"):\n",
    "    match1.append(i.text)\n",
    "\n",
    "match2 = []\n",
    "\n",
    "for i in soup5a.find_all('td',class_ = \"table-body__cell u-center-text\",limit=18):\n",
    "    match2.append(i.text)\n",
    "\n",
    "matches = match1 + match2[0::2]\n",
    "\n",
    "#matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1ce1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points:\n",
    "\n",
    "pts1 = []\n",
    "\n",
    "for i in soup5a.find_all('td',class_ = \"rankings-block__banner--points\"):\n",
    "    pts1.append(i.text)\n",
    "\n",
    "pts2 = []\n",
    "\n",
    "for i in soup5a.find_all('td',class_=\"table-body__cell u-center-text\",limit=18):\n",
    "    pts2.append(i.text)\n",
    "\n",
    "points = pts1 + pts2[1::2]\n",
    "\n",
    "#points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99fb273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings:\n",
    "\n",
    "rate1 = []\n",
    "\n",
    "for i in soup5a.find_all('td',class_ = \"rankings-block__banner--rating u-text-right\"):\n",
    "    rate1.append(i.text)\n",
    "    \n",
    "rate1[-1] = rate1[-1].strip()\n",
    "\n",
    "rate2 = []\n",
    "\n",
    "for i in soup5a.find_all('td',class_=\"table-body__cell u-text-right rating\",limit=9):\n",
    "    rate2.append(i.text)\n",
    "\n",
    "ratings = rate1 + rate2\n",
    "\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6642e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings),len(points),len(matches),len(Team))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2595538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEAM_RANK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>34</td>\n",
       "      <td>3,802</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Teams Matches Points Ratings\n",
       "TEAM_RANK                                     \n",
       "1               England      27  3,226     119\n",
       "2           New Zealand      22  2,508     114\n",
       "3                 India      34  3,802     112\n",
       "4              Pakistan      22  2,354     107\n",
       "5             Australia      29  3,071     106\n",
       "6          South Africa      24  2,392     100\n",
       "7            Bangladesh      30  2,753      92\n",
       "8             Sri Lanka      29  2,658      92\n",
       "9           West Indies      41  2,902      71\n",
       "10          Afghanistan      18  1,238      69"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5a = pd.DataFrame({'Teams' :Team,'Matches' : matches,'Points' : points,\"Ratings\" : ratings,})\n",
    "df5a.index += 1\n",
    "df5a.index.name = \"TEAM_RANK\"\n",
    "df5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4415186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0abcb3b",
   "metadata": {},
   "source": [
    "**b) Top 10 ODI Batsmen along with the records of their team and rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8358eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "page5b = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup5b = BeautifulSoup(page5b.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7bc2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batsmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a0d38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bat1 = []\n",
    "\n",
    "for i in soup5b.find_all('div',class_ = \"rankings-block__banner--name\",limit=1):\n",
    "    bat1.append(i.text)\n",
    "#bat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5af46c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batter = soup5b.find_all('td',class_=\"table-body__cell name\",limit=9)\n",
    "\n",
    "Batsmen = []\n",
    "\n",
    "for i in Batter:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Batsmen.append(j.text)\n",
    "#Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1283c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batter = bat1 + Batsmen\n",
    "#best_batter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44140511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2df24f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "team1 = []\n",
    "\n",
    "for i in soup5b.find_all('div',class_ = \"rankings-block__banner--nationality\",limit=1):\n",
    "    team1.append(i.text[2:5].replace(\"\\n\",\"\"))\n",
    "#team1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "422f90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_all = []\n",
    "\n",
    "for i in soup5b.find_all('span',class_ = \"table-body__logo-text\",limit=9):\n",
    "    team_all.append(i.text)\n",
    "#team_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f630e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team = team1 + team_all\n",
    "#Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "721c8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96aa4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat1 = []\n",
    "\n",
    "for i in soup5b.find_all('div',class_ = \"rankings-block__banner--rating\",limit=1):\n",
    "    rat1.append(i.text)\n",
    "#rat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f59f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_all = []\n",
    "\n",
    "for i in soup5b.find_all('td',class_ = \"table-body__cell u-text-right rating\",limit=9):\n",
    "    rat_all.append(i.text)\n",
    "#rat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de1f3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings = rat1 + rat_all\n",
    "#Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0dd7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21ae6eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BATTER</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAT_RANK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         BATTER COUNTRY Ratings\n",
       "BAT_RANK                                       \n",
       "1                    Babar Azam     PAK     890\n",
       "2                   Imam-ul-Haq     PAK     779\n",
       "3         Rassie van der Dussen      SA     766\n",
       "4               Quinton de Kock      SA     759\n",
       "5                Jonny Bairstow     ENG     732\n",
       "6                  David Warner     AUS     725\n",
       "7                   Virat Kohli     IND     722\n",
       "8                  Rohit Sharma     IND     718\n",
       "9                   Ross Taylor      NZ     701\n",
       "10                  Steve Smith     AUS     697"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5b = pd.DataFrame({'BATTER':best_batter,\"COUNTRY\":Team,'Ratings':Ratings})\n",
    "df5b.index += 1\n",
    "df5b.index.name = \"BAT_RANK\"\n",
    "df5b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d7c17",
   "metadata": {},
   "source": [
    "**c) Top 10 ODI bowlers along with the records of their team and rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50b17507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bowlers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02749e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = []\n",
    "\n",
    "for i in soup5b.find_all('div',class_ = \"rankings-block__banner--name\"):\n",
    "    b1.append(i.text.split(','))\n",
    "bowl1 = b1[1]\n",
    "#bowl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c11371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowl_all = []\n",
    "\n",
    "for i in soup5b.find_all('td',class_ = \"table-body__cell name\"):\n",
    "    bowl_all.append(i.text.replace(\"\\n\",\"\"))\n",
    "#bowl_all[9:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91a558ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best__bowler = bowl1 + bowl_all[9:18]\n",
    "#best__bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b504737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5bc4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = []\n",
    "\n",
    "for i in soup5b.find_all('div',class_ = \"rankings-block__banner--nationality\"):\n",
    "    t1.append(i.text[2:5].replace(\"\\n\",\"\").split(','))\n",
    "team1 = t1[1]\n",
    "#team1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7774420",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_all = []\n",
    "\n",
    "for i in soup5b.find_all('span',class_ = \"table-body__logo-text\"):\n",
    "    team_all.append(i.text)\n",
    "#team_all[9:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a87eaef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team_bowl = team1 + team_all[9:18]\n",
    "#Team_bowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a397669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85f580f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = []\n",
    "\n",
    "for i in soup5b.find_all('div',class_ = \"rankings-block__banner--rating\"):\n",
    "    r1.append(i.text.split(','))\n",
    "rat1 = r1[1]\n",
    "#rat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71473492",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_all = []\n",
    "\n",
    "for i in soup5b.find_all('td',class_ = \"table-body__cell u-text-right rating\"):\n",
    "    rat_all.append(i.text)\n",
    "#rat_all[9:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbe618c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings_bowl = rat1 + rat_all[9:18]\n",
    "#Ratings_bowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6b1d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b350ac08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOWLER</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOWL_RANK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BOWLER COUNTRY Ratings\n",
       "BOWL_RANK                                  \n",
       "1               Trent Boult      NZ     775\n",
       "2            Josh Hazlewood     AUS     718\n",
       "3          Mujeeb Ur Rahman     AFG     676\n",
       "4            Shaheen Afridi     PAK     661\n",
       "5             Mohammad Nabi     AFG     657\n",
       "6              Mehedi Hasan     BAN     655\n",
       "7                Matt Henry      NZ     654\n",
       "8            Mitchell Starc     AUS     653\n",
       "9               Rashid Khan     AFG     651\n",
       "10           Jasprit Bumrah     IND     642"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5c = pd.DataFrame({'BOWLER':best__bowler,\"COUNTRY\":Team_bowl,'Ratings':Ratings_bowl})\n",
    "df5c.index += 1\n",
    "df5c.index.name = \"BOWL_RANK\"\n",
    "df5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ac285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08b2032c",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "- a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "- b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "- c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ba217",
   "metadata": {},
   "source": [
    "**a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27e3a9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>170               ...</td>\n",
       "      <td>3,061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>3,098</td>\n",
       "      <td>116</td>\n",
       "      <td>3,098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2,904</td>\n",
       "      <td>101</td>\n",
       "      <td>2,904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>2,820</td>\n",
       "      <td>78</td>\n",
       "      <td>2,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2,425</td>\n",
       "      <td>47</td>\n",
       "      <td>2,425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches                                             Rating  \\\n",
       "0     Australia      18                              170               ...   \n",
       "1  South Africa      26                                                119   \n",
       "2       England   3,098                                                116   \n",
       "3         India      25                                                104   \n",
       "4   New Zealand   2,904                                                101   \n",
       "5   West Indies      27                                                 97   \n",
       "6    Bangladesh   2,820                                                 78   \n",
       "7      Pakistan      24                                                 59   \n",
       "8       Ireland   2,425                                                 47   \n",
       "9     Sri Lanka      24                                                 44   \n",
       "\n",
       "  Points  \n",
       "0  3,061  \n",
       "1     26  \n",
       "2  3,098  \n",
       "3     25  \n",
       "4  2,904  \n",
       "5     27  \n",
       "6  2,820  \n",
       "7     24  \n",
       "8  2,425  \n",
       "9     24  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "resp = requests.get(url)\n",
    "\n",
    "SOUP= BeautifulSoup(resp.content, 'lxml')\n",
    "\n",
    "# Creating empty list\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "# Extracting Team Name\n",
    "Country = SOUP.find_all('span',class_=\"u-hide-phablet\")\n",
    "for i in Country:\n",
    "    Team.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Team=Team[0:10]\n",
    "    \n",
    "# Extracting No of Matches    \n",
    "match=SOUP.find_all('td',class_='rankings-block__banner--matches')\n",
    "matchs=SOUP.find_all('td',class_='table-body__cell u-center-text')\n",
    "mtc = match + matchs\n",
    "for i in  mtc:\n",
    "    Matches.append(i.text)\n",
    "    Matches=Matches[0:10]\n",
    "    \n",
    "# Extracting Points gain    \n",
    "pt=SOUP.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "pts= SOUP.find_all('td',class_ =\"table-body__cell u-center-text\")\n",
    "Point= pt + pts\n",
    "for i in Point:\n",
    "    Points.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Points=Points[0:10]\n",
    "    \n",
    "# Extracting Rating\n",
    "rat=SOUP.find_all('td',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "rating = SOUP.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "RATING=rat + rating\n",
    "for i in RATING:\n",
    "    Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Rating=Rating[0:10]\n",
    "Rating\n",
    "\n",
    "# Creating dataframe to store data\n",
    "ODI=pd.DataFrame({})\n",
    "ODI['Country']=Team\n",
    "ODI['Matches']=Matches\n",
    "ODI['Rating']=Rating\n",
    "ODI['Points']=Points\n",
    "ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07378622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26d25c1a",
   "metadata": {},
   "source": [
    "**b) Top 10 women’s ODI Batting players along with the records of their team and rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ecfa56c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td></td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking          Player_Name  \\\n",
       "0   \\n\\n\\n                            1\\n         ...         Alyssa Healy   \n",
       "1                                       2         ...          Beth Mooney   \n",
       "2                                       3         ...      Laura Wolvaardt   \n",
       "3                                       4         ...       Natalie Sciver   \n",
       "4                                       5         ...     Harmanpreet Kaur   \n",
       "5                                       6         ...      Smriti Mandhana   \n",
       "6                                       7         ...          Meg Lanning   \n",
       "7                                       8         ...       Rachael Haynes   \n",
       "8                                       9         ...    Amy Satterthwaite   \n",
       "9                                       10        ...  Chamari Athapaththu   \n",
       "10                                      11        ...         Ellyse Perry   \n",
       "\n",
       "   Team Rating  \n",
       "0          785  \n",
       "1   AUS    749  \n",
       "2    SA    732  \n",
       "3   ENG    725  \n",
       "4   IND    716  \n",
       "5   IND    714  \n",
       "6   AUS    710  \n",
       "7   AUS    701  \n",
       "8    NZ    661  \n",
       "9    SL    655  \n",
       "10  AUS    642  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'}\n",
    "response = requests.get(url)\n",
    "soup= BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Dataframe:\n",
    "ODI_Batmans=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "ODI_Batmans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aefc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc050fd",
   "metadata": {},
   "source": [
    "**c) Top 10 women’s ODI all-rounder along with the records of their team and rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "766c45d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td></td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        ...</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking          Player_Name  \\\n",
       "0   \\n\\n\\n                            1\\n         ...    Sophie Ecclestone   \n",
       "1                                       2         ...        Jess Jonassen   \n",
       "2                                       3         ...         Megan Schutt   \n",
       "3                                       4         ...       Shabnim Ismail   \n",
       "4                                       5         ...       Jhulan Goswami   \n",
       "5                                       6         ...      Hayley Matthews   \n",
       "6                                       7         ...           Kate Cross   \n",
       "7                                       8         ...       Ayabonga Khaka   \n",
       "8                                       9         ...  Rajeshwari Gayakwad   \n",
       "9                                       10        ...       Marizanne Kapp   \n",
       "10                                      11        ...          Amelia Kerr   \n",
       "\n",
       "   Team Rating  \n",
       "0          739  \n",
       "1   AUS    725  \n",
       "2   AUS    722  \n",
       "3    SA    722  \n",
       "4   IND    698  \n",
       "5    WI    671  \n",
       "6   ENG    657  \n",
       "7    SA    634  \n",
       "8   IND    617  \n",
       "9    SA    598  \n",
       "10   NZ    594  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'}\n",
    "response = requests.get(url)\n",
    "soup= BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Bowling=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "ODI_Bowling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1957222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "facc83c1",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "- i) Headline\n",
    "- ii) Time\n",
    "- iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "344dc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "url7 = 'https://www.cnbc.com/world/?region=world'\n",
    "page7 = requests.get(url7)\n",
    "htmlContent7 = page7.content\n",
    "soup7 = BeautifulSoup(htmlContent7,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92762b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4cd4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Head = []\n",
    "\n",
    "for i in soup7.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    Head.append(i.text)\n",
    "#Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "83312929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49f737ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time = []\n",
    "\n",
    "for i in soup7.find_all('span',class_=\"LatestNews-wrapper\"):\n",
    "    Time.append(i.text)\n",
    "#Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4084ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iii) News Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6eec44e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup7.find_all('a',class_ = \"LatestNews-headline\")\n",
    "urls = [x['href'] for x in links]\n",
    "#urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0e5ab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Head),len(urls),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bfa30383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obesity drugs are winning more support among d...</td>\n",
       "      <td>49 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/obesity-drugs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inflation to dampen holiday spending, retail t...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/inflation-to-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump advisor Patel granted immunity to testif...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/trump-news-kas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American billionaires spent a record $880 mill...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/american-billi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022 election spending set to top $16.7 billio...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/2022-midterm-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bezos sued by ex-housekeeper over working cond...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/amazon-founder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NBA Commissioner Adam Silver speaks out agains...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/nba-commission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stocks are being punished more harshly for mis...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/investors-are-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stocks making the biggest moves midday: Under ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NYC's salary transparency law is off to a rock...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/nycs-new-salar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon pauses hiring for corporate workforce</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/amazon-pauses-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Short seller Jim Chanos says this 'crummy' com...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/short-seller-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Retail investors are dumping most of Big Tech ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/retail-investo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>We're exiting a chip stock to raise cash in ca...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/were-exiting-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Value investors make a big comeback with one o...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/value-investor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jeep-maker Stellantis expects raw material inf...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/jeep-maker-ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Investing in Space: NASA and SpaceX need each ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/investing-in-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Major glaciers in Kilimanjaro and Yosemite wil...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/major-glaciers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNBC cancels 'The News with Shepard Smith' to ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/cnbc-cancels-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lyft cuts 13% of its workforce</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/lyft-cuts-13pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2 takeaways from our daily meeting: Selling in...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/2-takeaways-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tenbagger stocks that Wall Street believes can...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/tenbagger-stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Accused Pelosi attacker could be deported afte...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/accused-paul-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Altice USA stock sinks after tough third quart...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/altice-usa-sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Close to 26 million Americans have applied for...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/close-to-26-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UK faces longest recession since records began...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/bank-of-englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What to do if you test positive for Covid righ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/what-to-do-if-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ukraine government is seeking alternatives to ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/ukraine-govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Don't make these 5 virtual interview mistakes ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/the-5-virtual-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Magic mushroom compound psilocybin can help tr...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/11/03/magic-mushroom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   Obesity drugs are winning more support among d...   49 Min Ago   \n",
       "1   Inflation to dampen holiday spending, retail t...   1 Hour Ago   \n",
       "2   Trump advisor Patel granted immunity to testif...   1 Hour Ago   \n",
       "3   American billionaires spent a record $880 mill...   1 Hour Ago   \n",
       "4   2022 election spending set to top $16.7 billio...  2 Hours Ago   \n",
       "5   Bezos sued by ex-housekeeper over working cond...  2 Hours Ago   \n",
       "6   NBA Commissioner Adam Silver speaks out agains...  2 Hours Ago   \n",
       "7   Stocks are being punished more harshly for mis...  2 Hours Ago   \n",
       "8   Stocks making the biggest moves midday: Under ...  2 Hours Ago   \n",
       "9   NYC's salary transparency law is off to a rock...  2 Hours Ago   \n",
       "10       Amazon pauses hiring for corporate workforce  2 Hours Ago   \n",
       "11  Short seller Jim Chanos says this 'crummy' com...  2 Hours Ago   \n",
       "12  Retail investors are dumping most of Big Tech ...  2 Hours Ago   \n",
       "13  We're exiting a chip stock to raise cash in ca...  3 Hours Ago   \n",
       "14  Value investors make a big comeback with one o...  3 Hours Ago   \n",
       "15  Jeep-maker Stellantis expects raw material inf...  3 Hours Ago   \n",
       "16  Investing in Space: NASA and SpaceX need each ...  3 Hours Ago   \n",
       "17  Major glaciers in Kilimanjaro and Yosemite wil...  3 Hours Ago   \n",
       "18  CNBC cancels 'The News with Shepard Smith' to ...  3 Hours Ago   \n",
       "19                     Lyft cuts 13% of its workforce  3 Hours Ago   \n",
       "20  2 takeaways from our daily meeting: Selling in...  3 Hours Ago   \n",
       "21  Tenbagger stocks that Wall Street believes can...  4 Hours Ago   \n",
       "22  Accused Pelosi attacker could be deported afte...  4 Hours Ago   \n",
       "23  Altice USA stock sinks after tough third quart...  4 Hours Ago   \n",
       "24  Close to 26 million Americans have applied for...  4 Hours Ago   \n",
       "25  UK faces longest recession since records began...  4 Hours Ago   \n",
       "26  What to do if you test positive for Covid righ...  4 Hours Ago   \n",
       "27  Ukraine government is seeking alternatives to ...  4 Hours Ago   \n",
       "28  Don't make these 5 virtual interview mistakes ...  5 Hours Ago   \n",
       "29  Magic mushroom compound psilocybin can help tr...  5 Hours Ago   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/11/03/obesity-drugs-...  \n",
       "1   https://www.cnbc.com/2022/11/03/inflation-to-d...  \n",
       "2   https://www.cnbc.com/2022/11/03/trump-news-kas...  \n",
       "3   https://www.cnbc.com/2022/11/03/american-billi...  \n",
       "4   https://www.cnbc.com/2022/11/03/2022-midterm-e...  \n",
       "5   https://www.cnbc.com/2022/11/03/amazon-founder...  \n",
       "6   https://www.cnbc.com/2022/11/03/nba-commission...  \n",
       "7   https://www.cnbc.com/2022/11/03/investors-are-...  \n",
       "8   https://www.cnbc.com/2022/11/03/stocks-making-...  \n",
       "9   https://www.cnbc.com/2022/11/03/nycs-new-salar...  \n",
       "10  https://www.cnbc.com/2022/11/03/amazon-pauses-...  \n",
       "11  https://www.cnbc.com/2022/11/03/short-seller-j...  \n",
       "12  https://www.cnbc.com/2022/11/03/retail-investo...  \n",
       "13  https://www.cnbc.com/2022/11/03/were-exiting-a...  \n",
       "14  https://www.cnbc.com/2022/11/03/value-investor...  \n",
       "15  https://www.cnbc.com/2022/11/03/jeep-maker-ste...  \n",
       "16  https://www.cnbc.com/2022/11/03/investing-in-s...  \n",
       "17  https://www.cnbc.com/2022/11/03/major-glaciers...  \n",
       "18  https://www.cnbc.com/2022/11/03/cnbc-cancels-t...  \n",
       "19  https://www.cnbc.com/2022/11/03/lyft-cuts-13pe...  \n",
       "20  https://www.cnbc.com/2022/11/03/2-takeaways-fr...  \n",
       "21  https://www.cnbc.com/2022/11/03/tenbagger-stoc...  \n",
       "22  https://www.cnbc.com/2022/11/03/accused-paul-p...  \n",
       "23  https://www.cnbc.com/2022/11/03/altice-usa-sto...  \n",
       "24  https://www.cnbc.com/2022/11/03/close-to-26-mi...  \n",
       "25  https://www.cnbc.com/2022/11/03/bank-of-englan...  \n",
       "26  https://www.cnbc.com/2022/11/03/what-to-do-if-...  \n",
       "27  https://www.cnbc.com/2022/11/03/ukraine-govern...  \n",
       "28  https://www.cnbc.com/2022/11/03/the-5-virtual-...  \n",
       "29  https://www.cnbc.com/2022/11/03/magic-mushroom...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing data in Dataframe\n",
    "df7 = pd.DataFrame({'Headline':Head,'Time':Time, 'News Link':urls})\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b9274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0152e820",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days. https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles. Scrape below mentioned details :\n",
    "- i) Paper Title \n",
    "- ii) Authors\n",
    "- iii) Published Date \n",
    "- iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e4357bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url8 = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "page8 = requests.get(url8)\n",
    "htmlContent8 = page8.content\n",
    "soup8 = BeautifulSoup(htmlContent8,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44e28393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) Paper Title\n",
    "\n",
    "Title = []\n",
    "\n",
    "for i in soup8.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    Title.append(i.text)\n",
    "#Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb8af1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) Authors\n",
    "\n",
    "Authors = []\n",
    "\n",
    "for i in soup8.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    Authors.append(i.text)\n",
    "#Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7fce2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iii) Published Date\n",
    "\n",
    "Published_date = []\n",
    "\n",
    "for i in soup8.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    Published_date.append(i.text)\n",
    "#Published_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8aa144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv) Paper URL\n",
    "\n",
    "links = soup8.find_all('a',class_ = 'sc-5smygv-0 nrDZj')\n",
    "urls = [x['href'] for x in links]\n",
    "#urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b117131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Authors),len(Published_date),len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd2970a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "1                                    Reward is enough   \n",
       "2                           Making sense of raw input   \n",
       "3   Law and logic: A review from an argumentation ...   \n",
       "4              Creativity and artificial intelligence   \n",
       "5   Artificial cognition for social human–robot in...   \n",
       "6   Explanation in artificial intelligence: Insigh...   \n",
       "7                       Making sense of sensory input   \n",
       "8   Conflict-based search for optimal multi-agent ...   \n",
       "9   Between MDPs and semi-MDPs: A framework for te...   \n",
       "10  The Hanabi challenge: A new frontier for AI re...   \n",
       "11  Evaluating XAI: A comparison of rule-based and...   \n",
       "12           Argumentation in artificial intelligence   \n",
       "13  Algorithms for computing strategies in two-pla...   \n",
       "14      Multiple object tracking: A literature review   \n",
       "15  Selection of relevant features and examples in...   \n",
       "16  A survey of inverse reinforcement learning: Ch...   \n",
       "17  Explaining individual predictions when feature...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  Integrating social power into the decision-mak...   \n",
       "20  “That's (not) the output I expected!” On the r...   \n",
       "21  Explaining black-box classifiers using post-ho...   \n",
       "22  Algorithm runtime prediction: Methods & evalua...   \n",
       "23              Wrappers for feature subset selection   \n",
       "24  Commonsense visual sensemaking for autonomous ...   \n",
       "25         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "1   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "2           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "3                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "4                                 Boden, Margaret A.      August 1998   \n",
       "5     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "6                                        Miller, Tim    February 2019   \n",
       "7   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "8   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "9   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "10        Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "11  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "12               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "13       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "14             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "15                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "16                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "17      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "18  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "19    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "20                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "21  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "22  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "23                      Kohavi, Ron, John, George H.    December 1997   \n",
       "24  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "25                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  \n",
       "25  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing data in Dataframe:\n",
    "df8 = pd.DataFrame({'Paper Title':Title,'Authors':Authors, 'Published Date':Published_date, 'Paper URL':urls})\n",
    "df8.index += 1\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd00c87",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "\n",
    "- i) Restaurant name\n",
    "- ii) Cuisine\n",
    "- iii) Location \n",
    "- iv) Ratings\n",
    "- v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1fd3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "url9 = \"https://www.dineout.co.in/delhi-restaurants/buffet-special\"\n",
    "\n",
    "page9 = requests.get(url9)\n",
    "\n",
    "htmlContent9 = page9.content\n",
    "\n",
    "soup9 = BeautifulSoup(htmlContent9,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0806cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i) Restaurant name\n",
    "\n",
    "Rest_name = []\n",
    "\n",
    "for i in soup9.find_all('a',class_ =\"restnt-name ellipsis\"):\n",
    "    Rest_name.append(i.text) \n",
    "\n",
    "#Rest_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cfde2409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soupZ = BeautifulSoup('<a href=\"/delhi-restaurants/chinese-cuisine\" data-w-onclick=\"stopClickPropagation|w1-restarant\">Chinese</a>','html.parser')\n",
    "soupZ.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7fe0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii) Cuisine \n",
    "\n",
    "Cusine_name = []\n",
    "\n",
    "for i in soup9.find_all('span',class_ = \"double-line-ellipsis\"):\n",
    "    Cusine_name.append(i.text.split('|')[1]) \n",
    "\n",
    "#Cusine_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5abde986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iii) Location\n",
    "\n",
    "loc = []\n",
    "\n",
    "for i in soup9.find_all('div',class_='restnt-loc ellipsis'):\n",
    "    loc.append(i.text) \n",
    "\n",
    "#loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2da09186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iv) Ratings:\n",
    "\n",
    "Rate = []\n",
    "\n",
    "for i in soup9.find_all('div',class_='restnt-rating rating-4'):\n",
    "    Rate.append(i.text) \n",
    "\n",
    "#Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f295d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v) Image URL:\n",
    "\n",
    "img = []\n",
    "\n",
    "for i in soup9.find_all('img',class_=\"no-img\"):\n",
    "    img.append(i.get('data-src'))\n",
    "    \n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ecaad1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant name                        Cuisine  \\\n",
       "1                   Castle Barbeque          Chinese, North Indian   \n",
       "2                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "3                   Castle Barbeque          Chinese, North Indian   \n",
       "4                        Cafe Knosh           Italian, Continental   \n",
       "5              The Barbeque Company          North Indian, Chinese   \n",
       "6                       India Grill          North Indian, Italian   \n",
       "7                    Delhi Barbeque                   North Indian   \n",
       "8  The Monarch - Bar Be Que Village                   North Indian   \n",
       "9                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "1                     Connaught Place, Central Delhi     4.1   \n",
       "2             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "4  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "5                 Gardens Galleria,Sector 38A, Noida       4   \n",
       "6               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "7     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.6   \n",
       "8  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "9   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df9 = pd.DataFrame({\"Restaurant name\": Rest_name,\"Cuisine\":Cusine_name,\"Location\":loc,\"Ratings\":Rate,\"Image URL\":img})\n",
    "df9.index += 1\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5a098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41233f6b",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "- i) Rank \n",
    "- ii) Publication\n",
    "- iii) h5-index\n",
    "- iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a51884b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5_index</th>\n",
       "      <th>h5_median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Publication h5_index h5_median\n",
       "RANK                                                                      \n",
       "1                                                Nature      444       667\n",
       "2                   The New England Journal of Medicine      432       780\n",
       "3                                               Science      401       614\n",
       "4     IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "5                                            The Lancet      354       635\n",
       "...                                                 ...      ...       ...\n",
       "96                         Journal of Business Research      145       233\n",
       "97                                     Molecular Cancer      145       209\n",
       "98                                              Sensors      145       201\n",
       "99                                Nature Climate Change      144       228\n",
       "100                     IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url10 = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "page10 = requests.get(url10)\n",
    "htmlContent10 = page10.content\n",
    "soup10 = BeautifulSoup(htmlContent10,'html.parser')\n",
    "\n",
    "# Creating Empty list\n",
    "Publication = [] \n",
    "h5_index = [] \n",
    "h5_median = [] \n",
    "\n",
    "# Extracting Data of respective blocks:\n",
    "Publication_block = soup10.find_all('td', class_ = 'gsc_mvt_t')\n",
    "h5_index_block = soup10.find_all('a', class_ = 'gs_ibl gsc_mp_anchor')\n",
    "h5_median_block = soup10.find_all('span', class_ = 'gs_ibl gsc_mp_anchor')\n",
    "\n",
    "# appending data into respective lists:\n",
    "Publication = [i.text for i in Publication_block]\n",
    "h5_index = [j.text for j in h5_index_block]\n",
    "h5_median = [k.text for k in h5_median_block]\n",
    "\n",
    "# Creating DataFrame:\n",
    "df10 = pd.DataFrame({'Publication':Publication,'h5_index':h5_index,'h5_median':h5_median})\n",
    "df10.index.name = \"RANK\"\n",
    "df10.index += 1\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ac795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579069e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
